{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19mt_ILxNf5OW96NPj2iU2S5qicxLbfpu",
      "authorship_tag": "ABX9TyOp36jcsL8zV68sMKVRGcX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee-messi/machine-learning/blob/main/cola_grammar_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --quiet\n",
        "!pip install tensorflow-hub --quiet\n",
        "!pip install tensorflow-text --quiet\n",
        "!pip install tensorflow-addons --quiet\n",
        "!pip install tensorflow-datasets --quiet"
      ],
      "metadata": {
        "id": "u5lnTCkSPEbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9845a61-c129-4378-d734-d094128689b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.6.11 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "orbax-checkpoint 0.2.6 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\""
      ],
      "metadata": {
        "id": "T_5ey_StOQgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2f47fa-c307-4dd6-9af1-a26e6849d038"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recommended.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-KR1d2fP0ff",
        "outputId": "c4a34677-09c9-491c-9d22-fa2ca070e026"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import CoLA (The Corpus of Linguistic Acceptability) Data"
      ],
      "metadata": {
        "id": "Da8AGPhK2yzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CoLA is a collection of sentences that has been annotated for acceptability. The sentences are coded/labeled 1 if the sentence is grammatically acceptable or correct, and they are coded 0 if the sentence is grammatically wrong. You can access the publicly available corpus using the link [here](https://nyu-mll.github.io/CoLA/). First, we are going to import the datasets. The datasets are provided in **.tsv** format which can be imported using the **read_csv()** function."
      ],
      "metadata": {
        "id": "8kpW_bAY25mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('drive/MyDrive/Colab Notebooks/cola-grammar/in_domain_train.tsv',\n",
        "                    sep = '\\t', header = None)\n",
        "val = pd.read_csv('drive/MyDrive/Colab Notebooks/cola-grammar/in_domain_dev.tsv',\n",
        "                  sep = '\\t', header = None)\n",
        "test = pd.read_csv('drive/MyDrive/Colab Notebooks/cola-grammar/out_of_domain_dev.tsv',\n",
        "                   sep = '\\t', header = None)"
      ],
      "metadata": {
        "id": "A7EtWaOqXdC0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns = ['misc', 'labels', 'na', 'text']\n",
        "val.columns = ['misc', 'labels', 'na', 'text']\n",
        "test.columns = ['misc', 'labels', 'na', 'text']"
      ],
      "metadata": {
        "id": "A47VxiErc66F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'{}{}{}'.format(train.shape, val.shape, test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "hMbIOAoGZ_4j",
        "outputId": "92dc6358-91b0-430d-b2ca-1315ef214a84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(8551, 4)(527, 4)(516, 4)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we are going to inspect the training dataset to ensure that it is balanced - the number of sentences that are grammatically correct and wrong are equal. This is so that the classifier is not biased."
      ],
      "metadata": {
        "id": "INKwyclWGXjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.labels.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MlOFWP7GlNq",
        "outputId": "f727e5c1-7107-425a-96e6-bff346dca3aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    6023\n",
              "0    2528\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 6,023 sentences with label 1 and 2,528 sentences with label 0. Let's balance these out."
      ],
      "metadata": {
        "id": "r_8ADa9MGqN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.groupby('labels').sample(1500)"
      ],
      "metadata": {
        "id": "9JA_a_NKx46r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we are going to implement the **df_to_dataset()** function to create a **tf.data.Dataset** using the balanced reviews dataset. This allows us to map the features in the pandas dataframe to features that are more appropriate for training. You can read more about this and check out the function that is used to perform this task [here](https://www.tensorflow.org/tutorials/structured_data/feature_columns). Then, we are going to map the training, validation, and test datasets using the function. Note that depending on the features that you use in the model, you may have to modify parts of the function."
      ],
      "metadata": {
        "id": "bNCpjs5GHnAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_dataset(dataframe, shuffle = True, batch_size = 128):\n",
        "    df = dataframe.copy()\n",
        "    labels = df.labels\n",
        "    df = df.text\n",
        "    ds = tf.data.Dataset.from_tensor_slices((df, labels))\n",
        "    if shuffle == True:\n",
        "        ds = ds.shuffle(buffer_size = len(df))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return(ds)"
      ],
      "metadata": {
        "id": "UalPWlvleViL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = df_to_dataset(train)\n",
        "val_ds = df_to_dataset(val)\n",
        "test_ds = df_to_dataset(test)"
      ],
      "metadata": {
        "id": "jYRIqtO4es4C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier Model using BERT"
      ],
      "metadata": {
        "id": "MTTBLbwuHxeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ],
      "metadata": {
        "id": "E7PqElg0QjI9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "bert_encoder = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "wMu9KRFNQv_b"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\n",
        "encoder_input = bert_preprocess(text_input)\n",
        "encoder_output = bert_encoder(encoder_input)\n",
        "\n",
        "l = tf.keras.layers.Dense(100, activation = 'relu')(encoder_output['pooled_output'])\n",
        "l = tf.keras.layers.Dropout(0.3)(l)\n",
        "l = tf.keras.layers.Dense(50, activation = 'relu')(l)\n",
        "l = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ],
      "metadata": {
        "id": "I9pyoNzuRoSx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005),\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "SJbPZyzDReGA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "W9D5z-37ATi_",
        "outputId": "ff9c6bbc-f159-4a0f-da83-a3389397728d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)     {'input_type_ids':   0           ['input_6[0][0]']                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_2[2][0]',          \n",
            "                                None, 768),                       'keras_layer_2[2][1]',          \n",
            "                                 'sequence_output':               'keras_layer_2[2][2]']          \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)]}                                               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 100)          76900       ['keras_layer_3[2][13]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 100)          0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 50)           5050        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 1)            51          ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,564,242\n",
            "Trainable params: 82,001\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)"
      ],
      "metadata": {
        "id": "Ti7T68tZqMJI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,\n",
        "                    validation_data = val_ds,\n",
        "                    epochs = 30,\n",
        "                    callbacks = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRGHV0tUgPCd",
        "outputId": "e324162f-5a3e-4138-e066-084fbcb07840"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "24/24 [==============================] - 91s 4s/step - loss: 0.6959 - accuracy: 0.5383 - val_loss: 0.6999 - val_accuracy: 0.5446\n",
            "Epoch 2/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6780 - accuracy: 0.5667 - val_loss: 0.6455 - val_accuracy: 0.6490\n",
            "Epoch 3/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6771 - accuracy: 0.5840 - val_loss: 0.6957 - val_accuracy: 0.5085\n",
            "Epoch 4/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6703 - accuracy: 0.5863 - val_loss: 0.6524 - val_accuracy: 0.6471\n",
            "Epoch 5/30\n",
            "24/24 [==============================] - 86s 4s/step - loss: 0.6609 - accuracy: 0.5893 - val_loss: 0.6500 - val_accuracy: 0.6433\n",
            "Epoch 6/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6601 - accuracy: 0.6033 - val_loss: 0.6606 - val_accuracy: 0.6376\n",
            "Epoch 7/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6557 - accuracy: 0.6173 - val_loss: 0.5949 - val_accuracy: 0.7002\n",
            "Epoch 8/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6658 - accuracy: 0.5997 - val_loss: 0.6666 - val_accuracy: 0.5996\n",
            "Epoch 9/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6603 - accuracy: 0.5993 - val_loss: 0.6189 - val_accuracy: 0.7059\n",
            "Epoch 10/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6519 - accuracy: 0.6080 - val_loss: 0.7121 - val_accuracy: 0.5104\n",
            "Epoch 11/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6410 - accuracy: 0.6323 - val_loss: 0.6154 - val_accuracy: 0.6926\n",
            "Epoch 12/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6511 - accuracy: 0.6177 - val_loss: 0.5820 - val_accuracy: 0.7211\n",
            "Epoch 13/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6543 - accuracy: 0.6173 - val_loss: 0.6441 - val_accuracy: 0.6546\n",
            "Epoch 14/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6466 - accuracy: 0.6347 - val_loss: 0.6715 - val_accuracy: 0.5712\n",
            "Epoch 15/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6447 - accuracy: 0.6310 - val_loss: 0.5993 - val_accuracy: 0.7116\n",
            "Epoch 16/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6424 - accuracy: 0.6367 - val_loss: 0.6570 - val_accuracy: 0.6433\n",
            "Epoch 17/30\n",
            "24/24 [==============================] - 85s 4s/step - loss: 0.6373 - accuracy: 0.6383 - val_loss: 0.6116 - val_accuracy: 0.7135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model"
      ],
      "metadata": {
        "id": "mOr_A1eRIWys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['he good person is a monster in the woods.'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uSZNBmcg0cb",
        "outputId": "97869256-472d-404e-d721-306deaa8d1c8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44024056]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to test out the model using an example sentence that is grammatically wrong. As the prediction value is smaller than 0.5, the model predicted that the sentence is grammatically wrong. This time, we are going to evaluate the model using the test dataset:"
      ],
      "metadata": {
        "id": "uLuk9gKJIi2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiUftk-oIalO",
        "outputId": "40c5a85b-e682-459c-c90a-3f51e29936e3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 13s 2s/step - loss: 0.6089 - accuracy: 0.7054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6089155673980713, 0.7054263353347778]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model returned an accuracy of **70.54%**. This is a significant improvement from the previous model where the model now ranks around 6th among the models that have been used to perform the identical task on [Kaggle](https://www.kaggle.com/competitions/cola-in-domain-open-evaluation/leaderboard) (although the leaderboard is quite outdated)."
      ],
      "metadata": {
        "id": "H_YLvZLbKyKB"
      }
    }
  ]
}