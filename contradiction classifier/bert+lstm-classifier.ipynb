{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, re, random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport tensorflow_hub as hub\nimport tensorflow_text as text\n\nfrom transformers import BertTokenizer, TFDistilBertModel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-06T19:30:48.130230Z","iopub.execute_input":"2023-08-06T19:30:48.130506Z","iopub.status.idle":"2023-08-06T19:30:57.527198Z","shell.execute_reply.started":"2023-08-06T19:30:48.130479Z","shell.execute_reply":"2023-08-06T19:30:57.526173Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:30:57.528666Z","iopub.execute_input":"2023-08-06T19:30:57.529732Z","iopub.status.idle":"2023-08-06T19:30:57.622137Z","shell.execute_reply.started":"2023-08-06T19:30:57.529695Z","shell.execute_reply":"2023-08-06T19:30:57.620913Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"We are going to create a single text column where we concatenate the premise and the hypothesis, separated by \" [SEP] \". We are going to use the **sequence_output** of the BERT layer so that the classifier uses both word meaning and word order to determine if the premise and hypothesis are contradictory or not. ","metadata":{}},{"cell_type":"code","source":"train['text'] = train.premise + \" [SEP] \" + train.hypothesis","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:30:57.623815Z","iopub.execute_input":"2023-08-06T19:30:57.624190Z","iopub.status.idle":"2023-08-06T19:30:57.638273Z","shell.execute_reply.started":"2023-08-06T19:30:57.624155Z","shell.execute_reply":"2023-08-06T19:30:57.636623Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = np.split(train.sample(frac = 1), [int(0.8 * len(train))])","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:30:57.641157Z","iopub.execute_input":"2023-08-06T19:30:57.641803Z","iopub.status.idle":"2023-08-06T19:30:57.656173Z","shell.execute_reply.started":"2023-08-06T19:30:57.641768Z","shell.execute_reply":"2023-08-06T19:30:57.655270Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_df.text, train_df.label)).shuffle(len(train_df)).batch(64).prefetch(tf.data.AUTOTUNE)\nval_dataset = tf.data.Dataset.from_tensor_slices((val_df.text, val_df.label)).shuffle(len(val_df)).batch(64).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:40:24.240945Z","iopub.execute_input":"2023-08-06T19:40:24.241350Z","iopub.status.idle":"2023-08-06T19:40:24.277980Z","shell.execute_reply.started":"2023-08-06T19:40:24.241317Z","shell.execute_reply":"2023-08-06T19:40:24.277001Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(\"Number of observations in training data set: {}\".format(len(train_df)))\nprint(\"Number of observations in validation data set: {}\".format(len(val_df)))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:30:57.659498Z","iopub.execute_input":"2023-08-06T19:30:57.659799Z","iopub.status.idle":"2023-08-06T19:30:57.669294Z","shell.execute_reply.started":"2023-08-06T19:30:57.659775Z","shell.execute_reply":"2023-08-06T19:30:57.668232Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Number of observations in training data set: 9696\nNumber of observations in validation data set: 2424\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Build Model","metadata":{}},{"cell_type":"markdown","source":"As the data set that we are trying to classify contain texts that are written in other languages, we are going to use the **bert_multi_cased_L-12_H-768_A-12** model. To find out more about the model, refer to the documentation [here](https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4). ","metadata":{}},{"cell_type":"code","source":"preprocess_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\nencoder_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:33:07.580488Z","iopub.execute_input":"2023-08-06T19:33:07.581102Z","iopub.status.idle":"2023-08-06T19:33:36.572419Z","shell.execute_reply.started":"2023-08-06T19:33:07.581065Z","shell.execute_reply":"2023-08-06T19:33:36.571367Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"input_layer = tf.keras.layers.Input(shape = (), dtype = tf.string)\nbert_input = preprocess_layer(input_layer)\nbert_output = encoder_layer(bert_input)\n\noutput = tf.keras.layers.Dropout(0.3)(bert_output['sequence_output'])\noutput = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(output)\noutput = tf.keras.layers.Dense(3, activation = 'softmax')(output)\n\nmodel = tf.keras.Model(inputs = [input_layer], outputs = output)\nmodel.compile(optimizer = tf.keras.optimizers.AdamW(),\n              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:40:44.020051Z","iopub.execute_input":"2023-08-06T19:40:44.020431Z","iopub.status.idle":"2023-08-06T19:40:44.682689Z","shell.execute_reply.started":"2023-08-06T19:40:44.020397Z","shell.execute_reply":"2023-08-06T19:40:44.681495Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n                                                  patience = 2)\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath = 'model/best_performed_model.ckpt',\n    save_weights_only = True,\n    save_best_only = True,\n    monitor = 'val_loss',\n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:39:17.985932Z","iopub.execute_input":"2023-08-06T19:39:17.986698Z","iopub.status.idle":"2023-08-06T19:39:17.992925Z","shell.execute_reply.started":"2023-08-06T19:39:17.986650Z","shell.execute_reply":"2023-08-06T19:39:17.991826Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, \n                    validation_data = val_dataset,\n                    epochs = 30, \n                    callbacks = [early_stopping, model_checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2023-08-06T19:40:47.146473Z","iopub.execute_input":"2023-08-06T19:40:47.146921Z","iopub.status.idle":"2023-08-06T19:49:18.016433Z","shell.execute_reply.started":"2023-08-06T19:40:47.146886Z","shell.execute_reply":"2023-08-06T19:49:18.015490Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/30\n152/152 [==============================] - ETA: 0s - loss: 1.0795 - accuracy: 0.4060\nEpoch 1: val_loss improved from inf to 1.04090, saving model to model/best_performed_model.ckpt\n152/152 [==============================] - 116s 680ms/step - loss: 1.0795 - accuracy: 0.4060 - val_loss: 1.0409 - val_accuracy: 0.4575\nEpoch 2/30\n152/152 [==============================] - ETA: 0s - loss: 1.0140 - accuracy: 0.4867\nEpoch 2: val_loss improved from 1.04090 to 1.03031, saving model to model/best_performed_model.ckpt\n152/152 [==============================] - 101s 663ms/step - loss: 1.0140 - accuracy: 0.4867 - val_loss: 1.0303 - val_accuracy: 0.4773\nEpoch 3/30\n152/152 [==============================] - ETA: 0s - loss: 0.9724 - accuracy: 0.5229\nEpoch 3: val_loss improved from 1.03031 to 1.02134, saving model to model/best_performed_model.ckpt\n152/152 [==============================] - 100s 658ms/step - loss: 0.9724 - accuracy: 0.5229 - val_loss: 1.0213 - val_accuracy: 0.4851\nEpoch 4/30\n152/152 [==============================] - ETA: 0s - loss: 0.9240 - accuracy: 0.5548\nEpoch 4: val_loss did not improve from 1.02134\n152/152 [==============================] - 97s 640ms/step - loss: 0.9240 - accuracy: 0.5548 - val_loss: 1.0306 - val_accuracy: 0.4905\nEpoch 5/30\n152/152 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.5912\nEpoch 5: val_loss did not improve from 1.02134\n152/152 [==============================] - 97s 638ms/step - loss: 0.8744 - accuracy: 0.5912 - val_loss: 1.0398 - val_accuracy: 0.4856\n","output_type":"stream"}]}]}